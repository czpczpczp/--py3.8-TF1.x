# Did the Model Understand the Question 

衡量一个系统优劣的标准方法是评估它在一个测试集上的误差。只有当测试集代表了底层的真实世界任务时，高准确度才表示一个好的模型。大多数任务都有大量的测试和训练集，很难手动检查它们是否代表真实世界。

本文中，提出了一种技术来分析深度学习模型对疑问词的敏感性。

例子：考虑一下这个问题:“建筑两边的白砖有多对称?”(如图1中对应的图像)。我们研究的系统得到了正确的答案(“very”)。但是，我们发现(使用归因方法)这个系统只依赖于少数几个词，如“如何”和“砖块”。事实上，我们可以针对系统出错的同一形象构造对抗性的问题。例如，“建筑两边的白砖有多圆?”返回相同的答案(“very”)。（这里我觉得就表明了模型对疑问词很敏感）

